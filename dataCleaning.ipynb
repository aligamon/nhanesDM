{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import scale, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demoDF = pd.read_csv('./data/demographics.csv')\n",
    "quesDF = pd.read_csv('./data/questionnaire.csv')\n",
    "examDF = pd.read_csv('./data/examination.csv')\n",
    "medsDF = pd.read_csv('./data/medications.csv')\n",
    "labsDF= pd.read_csv('./data/labs.csv')\n",
    "dietDF= pd.read_csv('./data/diet.csv')\n",
    "\n",
    "medsDF = medsDF.groupby('SEQN').agg({'RXDUSE': 'sum', 'RXDDAYS': 'max'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF = demoDF.merge(quesDF, on='SEQN', how='inner')\n",
    "fullDF = fullDF.merge(medsDF, on='SEQN', how='inner')\n",
    "fullDF = fullDF.merge(labsDF, on='SEQN', how='left')\n",
    "fullDF = fullDF.merge(examDF, on='SEQN', how='left')\n",
    "fullDF = fullDF.merge(dietDF, on='SEQN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate dataset into different races\n",
    "\n",
    "nonwhiteDF= fullDF[fullDF['RIDRETH3'].isin([2,1,3,6,7])]\n",
    "whiteDF= fullDF[fullDF['RIDRETH3'].isin([3])]\n",
    "hispanicDF= fullDF[fullDF['RIDRETH3'].isin([1,2])]\n",
    "blackDF= fullDF[fullDF['RIDRETH3'].isin([4])]\n",
    "asianDF= fullDF[fullDF['RIDRETH3'].isin([6])]\n",
    "multiraceDF = fullDF[fullDF['RIDRETH3'].isin([7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listing how many patients are there based on races\n",
    "\n",
    "print(len(nonwhiteDF))\n",
    "print(len(whiteDF))\n",
    "print(len(hispanicDF))\n",
    "print(len(blackDF))\n",
    "print(len(asianDF))\n",
    "print(len(multiraceDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting columns that we would like to further study on\n",
    "\n",
    "deprCode = [\n",
    "    'SEQN', 'RIDRETH3', 'RIAGENDR', 'RIDAGEYR', 'DMDBORN4', 'DMDCITZN',\n",
    "    'DMDMARTL', 'DMDEDUC2', 'DMDHHSIZ', 'DMDFMSIZ', 'DBD895', 'DBD905',\n",
    "    'DBD910', 'CBD120', 'CBD130', 'DIQ010', 'DID040', 'FSDHH', 'FSD032C',\n",
    "    'PFQ061B', 'PFQ061D', 'PFQ061E', 'PAQ610', 'PAQ625', 'PAQ640', 'PAQ655',\n",
    "    'PAQ670', 'PAQ710', 'PAQ715', 'RXDUSE', 'RXDDAYS', 'SLD010H', 'SLQ050',\n",
    "    'SLQ060', 'SMD641', 'SMD650', 'SMD030', 'SMQ858', 'SMQ872', 'SMQ878',\n",
    "    'BMXBMI', 'WHQ070', 'WHD080A', 'WHD080B', 'WHD080D', 'WHD080M', 'MCQ025',\n",
    "    'MCQ160A', 'MCQ180A', 'MCQ160N', 'MCQ180N', 'MCQ160C', 'MCQ180C', 'MCQ160D',\n",
    "    'MCQ180D', 'MCQ160E', 'MCQ180E', 'MCQ160F', 'MCQ180F', 'MCQ220', 'BPXSY1',\n",
    "    'BPXDI1', 'BPQ080', 'LBXTR', 'LBDLDL', 'LBXTC', 'INDHHIN2', 'INDFMIN2',\n",
    "    'BPQ020', 'BMXWT', 'BMXHT', 'DIQ050', 'DIQ175A', 'BMXWAIST', 'DBD900',\n",
    "    'CBQ505', 'CBQ535', 'DPQ010', 'DPQ020', 'DPQ030', 'DPQ040', 'DPQ050',\n",
    "    'DPQ060', 'DPQ070', 'DPQ080', 'DPQ090', 'DPQ100', 'ALQ120Q', 'URXUMS',\n",
    "    'URDACT', 'LBXSTR', 'LBXSUA', 'LBXSCH', 'LBDSGLSI', 'DR1TKCAL', 'DR1TCARB',\n",
    "    'DR1TSUGR'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply all the selected columns to all different races\n",
    "\n",
    "fullDF = fullDF[deprCode]\n",
    "nonwhiteDF= nonwhiteDF[deprCode]\n",
    "whiteDF= whiteDF[deprCode]\n",
    "hispanicDF= hispanicDF[deprCode]\n",
    "blackDF= blackDF[deprCode]\n",
    "asianDF= asianDF[deprCode]\n",
    "multiraceDF = multiraceDF[deprCode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with missing values\n",
    "\n",
    "def replace_na_mental(df, col):\n",
    "    for c in col:\n",
    "        # Replace 7 and 9 with NaN in this column\n",
    "        df[c].replace({7: np.nan, 9: np.nan}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def replace_na(df, col):\n",
    "    df = df.copy()  \n",
    "    for c in col:\n",
    "        df.loc[:, c] = df[c].fillna(value=0).replace({10: 1, 11: 1, 13: 1, 34: 1})\n",
    "    return df\n",
    "\n",
    "def replace_na_7_9(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=0).replace({7: 0, 9: 0})\n",
    "  return df\n",
    "\n",
    "def replace_na_1_7_9(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=1).replace({7: 1, 9: 1})\n",
    "  return df\n",
    "\n",
    "def replace_na_2_7_9(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=0).replace({7: 0, 9: 0, 2:0})\n",
    "  return df\n",
    "\n",
    "def replace_na_2_3_7_9(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=0).replace({7: 0, 9: 0, 2:0, 1:2, 3:1})\n",
    "  return df\n",
    "\n",
    "\n",
    "def replace_na_77_99(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=0).replace({77: 0, 99: 0})\n",
    "  return df\n",
    "\n",
    "\n",
    "def replace_none_77_99(df, col):\n",
    "    for c in col:\n",
    "        df[c] = df[c].replace({77: None, 99: None})\n",
    "    return df\n",
    "\n",
    "def replace_na_77_99_8(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=0).replace({77: 0, 8:0, 99: 0})\n",
    "  return df\n",
    "\n",
    "def replace_na_777_999(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=0).replace({777: 0, 999: 0})\n",
    "  return df\n",
    "\n",
    "def replace_na_7777_9999(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=0).replace({7777: 0, 9999: 0})\n",
    "  return df\n",
    "\n",
    "def replace_na_77777_99999(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=0).replace({77777: 0, 99999: 0})\n",
    "  return df\n",
    "\n",
    "def replace_na_10_77_99(df, col):\n",
    "  for c in col:\n",
    "    df[c]= df[c].fillna(value=0).replace({77: 0, 99: 0, 10:1})\n",
    "  return df\n",
    "\n",
    "def replace_BPXSY1(df, col):\n",
    "    for c in col:\n",
    "     df[c]= df[c].fillna(value=115)\n",
    "    return df\n",
    "\n",
    "def replace_BPXDI1(df, col):\n",
    "    for c in col:\n",
    "     df[c]= df[c].fillna(value=75)\n",
    "    return df\n",
    "\n",
    "def replace_LBXTR(df, col):\n",
    "    for c in col:\n",
    "     df[c]= df[c].fillna(value=145)\n",
    "    return df\n",
    "\n",
    "def replace_LBDLDL(df, col):\n",
    "    for c in col:\n",
    "     df[c]= df[c].fillna(value=130)\n",
    "    return df\n",
    "\n",
    "def replace_LBXTC(df, col):\n",
    "    for c in col:\n",
    "     df[c]= df[c].fillna(value=200)\n",
    "    return df\n",
    "\n",
    "def replace_mean_age(df, col):\n",
    "  for c in col:\n",
    "    df.groupby('RIDAGEYR')[col].apply(lambda x: x.fillna(x.mean()))\n",
    "    return df\n",
    "\n",
    "def replace_mean_bmi(df, col):\n",
    "  for c in col:\n",
    "    df.groupby('newbmi')[col].apply(lambda x: x.fillna(x.mean()))\n",
    "    return df\n",
    "\n",
    "def calculate_bmi(row):\n",
    "    height_meters = row['BMXHT'] / 100  \n",
    "    bmi = row['BMXWT'] / (height_meters ** 2)  # Calculate BMI using the formula\n",
    "    return bmi\n",
    "\n",
    "\n",
    "def categorize_bmi(bmi):\n",
    "    if bmi < 25:\n",
    "        return 0\n",
    "    elif 25 <= bmi < 30:\n",
    "        return 1\n",
    "    elif bmi >= 30:\n",
    "        return 2\n",
    "\n",
    "def categorize_abdominal_obesity(row):\n",
    "    if row['RIAGENDR'] == 1 and row['BMXWAIST'] >= 102:\n",
    "        return 1\n",
    "    elif row['RIAGENDR'] == 2 and row['BMXWAIST'] >= 88:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "##########################################\n",
    "\n",
    "column_na = ['WHD080B' ,'WHD080D', 'WHD080M', 'WHD080A']\n",
    "fullDF = replace_na(fullDF, column_na)\n",
    "nonwhiteDF = replace_na(nonwhiteDF, column_na)\n",
    "whiteDF = replace_na(whiteDF, column_na)\n",
    "hispanicDF = replace_na(hispanicDF, column_na)\n",
    "blackDF = replace_na(blackDF, column_na)\n",
    "asianDF = replace_na(asianDF, column_na)\n",
    "multiraceDF = replace_na(multiraceDF, column_na)\n",
    "\n",
    "column_na_7_9 = ['DPQ010', 'DPQ020', 'DPQ030', 'DPQ040', 'DPQ050', 'DPQ060','DPQ070','DPQ080', 'DPQ090', 'DPQ100']\n",
    "fullDF = replace_na_7_9(fullDF, column_na_7_9)\n",
    "nonwhiteDF = replace_na_7_9(nonwhiteDF, column_na_7_9)\n",
    "whiteDF = replace_na_7_9(whiteDF, column_na_7_9)\n",
    "hispanicDF = replace_na_7_9(hispanicDF, column_na_7_9)\n",
    "blackDF = replace_na_7_9(blackDF, column_na_7_9)\n",
    "asianDF = replace_na_7_9(asianDF, column_na_7_9)\n",
    "multiraceDF = replace_na_7_9(multiraceDF, column_na_7_9)\n",
    "\n",
    "column_na_1_7_9 = ['PFQ061B' ,'PFQ061D', 'PFQ061E']\n",
    "fullDF = replace_na_1_7_9(fullDF, column_na_1_7_9)\n",
    "nonwhiteDF = replace_na_1_7_9(nonwhiteDF, column_na_1_7_9)\n",
    "whiteDF = replace_na_1_7_9(whiteDF, column_na_1_7_9)\n",
    "hispanicDF = replace_na_1_7_9(hispanicDF, column_na_1_7_9)\n",
    "blackDF = replace_na_1_7_9(blackDF, column_na_1_7_9)\n",
    "asianDF = replace_na_1_7_9(asianDF, column_na_1_7_9)\n",
    "multiraceDF = replace_na_1_7_9(multiraceDF, column_na_1_7_9)\n",
    "\n",
    "column_na_2_3_7_9 = ['DIQ010']\n",
    "fullDF = replace_na_2_3_7_9(fullDF, column_na_2_3_7_9)\n",
    "nonwhiteDF = replace_na_2_3_7_9(nonwhiteDF, column_na_2_3_7_9)\n",
    "whiteDF = replace_na_2_3_7_9(whiteDF, column_na_2_3_7_9)\n",
    "hispanicDF = replace_na_2_3_7_9(hispanicDF, column_na_2_3_7_9)\n",
    "blackDF = replace_na_2_3_7_9(blackDF, column_na_2_3_7_9)\n",
    "asianDF = replace_na_2_3_7_9(asianDF, column_na_2_3_7_9)\n",
    "multiraceDF = replace_na_2_3_7_9(multiraceDF, column_na_2_3_7_9)\n",
    "\n",
    "column_na_2_7_9 = ['SMQ858', 'SMQ872', 'SMQ878', 'BPQ020', \\\n",
    "   'BPQ080',  'RXDUSE', 'SLQ050',\\\n",
    "  'SLQ060', 'MCQ160A', 'MCQ160N', 'MCQ160C', 'MCQ160D', 'MCQ160E',\\\n",
    "   'MCQ160F', 'MCQ220','WHQ070', 'DIQ050','CBQ505', 'CBQ535' ]\n",
    "fullDF = replace_na_2_7_9(fullDF, column_na_2_7_9)\n",
    "nonwhiteDF = replace_na_2_7_9(nonwhiteDF, column_na_2_7_9)\n",
    "whiteDF = replace_na_2_7_9(whiteDF, column_na_2_7_9)\n",
    "hispanicDF = replace_na_2_7_9(hispanicDF, column_na_2_7_9)\n",
    "blackDF = replace_na_2_7_9(blackDF, column_na_2_7_9)\n",
    "asianDF = replace_na_2_7_9(asianDF, column_na_2_7_9)\n",
    "multiraceDF = replace_na_2_7_9(multiraceDF, column_na_2_7_9)\n",
    "\n",
    "column_na_77_99 = ['WHD080A','SMD641', 'PAQ610', 'PAQ625',  'PAQ640', 'PAQ655' ,'PAQ670'  ]\n",
    "fullDF = replace_na_77_99(fullDF, column_na_77_99)\n",
    "nonwhiteDF = replace_na_77_99(nonwhiteDF, column_na_77_99)\n",
    "whiteDF = replace_na_77_99(whiteDF, column_na_77_99)\n",
    "hispanicDF = replace_na_77_99(hispanicDF, column_na_77_99)\n",
    "blackDF = replace_na_77_99(blackDF, column_na_77_99)\n",
    "asianDF = replace_na_77_99(asianDF, column_na_77_99)\n",
    "multiraceDF = replace_na_77_99(multiraceDF, column_na_77_99)\n",
    "\n",
    "column_none_77_99 = ['INDHHIN2']\n",
    "fullDF = replace_none_77_99(fullDF, column_none_77_99)\n",
    "nonwhiteDF = replace_none_77_99(nonwhiteDF, column_none_77_99)\n",
    "whiteDF = replace_none_77_99(whiteDF, column_none_77_99)\n",
    "hispanicDF = replace_none_77_99(hispanicDF, column_none_77_99)\n",
    "blackDF = replace_none_77_99(blackDF, column_none_77_99)\n",
    "asianDF = replace_none_77_99(asianDF, column_none_77_99)\n",
    "multiraceDF = replace_none_77_99(multiraceDF, column_none_77_99)\n",
    "\n",
    "column_na_10_77_99 = [ 'DIQ175A' ]\n",
    "fullDF = replace_na_10_77_99(fullDF, column_na_10_77_99)\n",
    "nonwhiteDF = replace_na_10_77_99(nonwhiteDF, column_na_10_77_99)\n",
    "whiteDF = replace_na_10_77_99(whiteDF, column_na_10_77_99)\n",
    "hispanicDF = replace_na_10_77_99(hispanicDF, column_na_10_77_99)\n",
    "blackDF = replace_na_10_77_99(blackDF, column_na_10_77_99)\n",
    "asianDF = replace_na_10_77_99(asianDF, column_na_10_77_99)\n",
    "multiraceDF = replace_na_10_77_99(multiraceDF, column_na_10_77_99)\n",
    "\n",
    "column_na_77_99_8 = ['PAQ710' ,'PAQ715']\n",
    "fullDF = replace_na_77_99_8(fullDF, column_na_77_99_8)\n",
    "nonwhiteDF = replace_na_77_99_8(nonwhiteDF, column_na_77_99_8 )\n",
    "whiteDF = replace_na_77_99_8(whiteDF, column_na_77_99_8 )\n",
    "hispanicDF = replace_na_77_99_8(hispanicDF, column_na_77_99_8 )\n",
    "blackDF = replace_na_77_99_8(blackDF, column_na_77_99_8 )\n",
    "asianDF = replace_na_77_99_8(asianDF, column_na_77_99_8 )\n",
    "multiraceDF = replace_na_77_99_8(multiraceDF, column_na_77_99_8 )\n",
    "\n",
    "column_na_777_999 = ['DID040' ,'SMD650', 'SMD030',  'ALQ120Q']\n",
    "fullDF = replace_na_777_999(fullDF, column_na_777_999)\n",
    "nonwhiteDF = replace_na_777_999(nonwhiteDF, column_na_777_999 )\n",
    "whiteDF = replace_na_777_999(whiteDF, column_na_777_999 )\n",
    "hispanicDF = replace_na_777_999(hispanicDF, column_na_777_999 )\n",
    "blackDF = replace_na_777_999(blackDF, column_na_777_999 )\n",
    "asianDF = replace_na_777_999(asianDF, column_na_777_999 )\n",
    "multiraceDF = replace_na_777_999(multiraceDF, column_na_777_999 )\n",
    "\n",
    "column_na_7777_9999 = [  'RXDDAYS', 'MCQ180A', 'MCQ180N',\\\n",
    "                       'MCQ180C', 'MCQ180D', 'MCQ180E', 'MCQ180F', 'MCQ025', \\\n",
    "                       'DBD895', 'DBD900', 'DBD905', 'DBD910','DBD900','DBD905','DBD910'  ]\n",
    "fullDF = replace_na_7777_9999(fullDF, column_na_7777_9999)\n",
    "nonwhiteDF = replace_na_7777_9999(nonwhiteDF, column_na_7777_9999 )\n",
    "whiteDF = replace_na_7777_9999(whiteDF, column_na_7777_9999 )\n",
    "hispanicDF = replace_na_7777_9999(hispanicDF, column_na_7777_9999 )\n",
    "blackDF = replace_na_7777_9999(blackDF, column_na_7777_9999 )\n",
    "asianDF = replace_na_7777_9999(asianDF, column_na_7777_9999 )\n",
    "multiraceDF = replace_na_7777_9999(multiraceDF, column_na_7777_9999 )\n",
    "\n",
    "column_na_77777_99999 = ['CBD120', 'CBD130']\n",
    "fullDF = replace_na_77777_99999(fullDF, column_na_77777_99999)\n",
    "nonwhiteDF = replace_na_77777_99999(nonwhiteDF, column_na_77777_99999 )\n",
    "whiteDF = replace_na_77777_99999(whiteDF, column_na_77777_99999 )\n",
    "hispanicDF = replace_na_77777_99999(hispanicDF, column_na_77777_99999 )\n",
    "blackDF = replace_na_77777_99999(blackDF, column_na_77777_99999 )\n",
    "asianDF = replace_na_77777_99999(asianDF, column_na_77777_99999 )\n",
    "multiraceDF = replace_na_77777_99999(multiraceDF, column_na_77777_99999 )\n",
    "\n",
    "column_mean_age = [ 'BMXBMI', 'SLD010H', 'INDHHIN2', 'INDFMIN2']\n",
    "fullDF = replace_mean_age(fullDF, column_mean_age)\n",
    "nonwhiteDF = replace_mean_age(nonwhiteDF, column_mean_age )\n",
    "whiteDF = replace_mean_age(whiteDF, column_mean_age )\n",
    "hispanicDF = replace_mean_age(hispanicDF, column_mean_age )\n",
    "blackDF = replace_mean_age(blackDF, column_mean_age )\n",
    "asianDF = replace_mean_age(asianDF, column_mean_age )\n",
    "multiraceDF = replace_mean_age(multiraceDF, column_mean_age )\n",
    "\n",
    "\n",
    "column_BPXSY1 = ['BPXSY1']\n",
    "fullDF = replace_BPXSY1(fullDF, column_BPXSY1)\n",
    "nonwhiteDF = replace_BPXSY1(nonwhiteDF, column_BPXSY1 )\n",
    "whiteDF = replace_BPXSY1(whiteDF, column_BPXSY1 )\n",
    "hispanicDF = replace_BPXSY1(hispanicDF, column_BPXSY1 )\n",
    "blackDF = replace_BPXSY1(blackDF, column_BPXSY1 )\n",
    "asianDF = replace_BPXSY1(asianDF, column_BPXSY1 )\n",
    "multiraceDF = replace_BPXSY1(multiraceDF, column_BPXSY1 )\n",
    "\n",
    "\n",
    "\n",
    "column_BPXDI1 = ['BPXDI1']\n",
    "fullDF = replace_BPXDI1(fullDF, column_BPXDI1)\n",
    "nonwhiteDF = replace_BPXDI1(nonwhiteDF, column_BPXDI1 )\n",
    "whiteDF = replace_BPXDI1(whiteDF, column_BPXDI1 )\n",
    "hispanicDF = replace_BPXDI1(hispanicDF, column_BPXDI1 )\n",
    "blackDF = replace_BPXDI1(blackDF, column_BPXDI1 )\n",
    "asianDF = replace_BPXDI1(asianDF, column_BPXDI1 )\n",
    "multiraceDF = replace_BPXDI1(multiraceDF, column_BPXDI1 )\n",
    "\n",
    "column_LBXTR = ['LBXTR']\n",
    "fullDF = replace_LBXTR(fullDF, column_LBXTR)\n",
    "nonwhiteDF = replace_LBXTR(nonwhiteDF, column_LBXTR )\n",
    "whiteDF = replace_LBXTR(whiteDF, column_LBXTR )\n",
    "hispanicDF = replace_LBXTR(hispanicDF, column_LBXTR )\n",
    "blackDF = replace_LBXTR(blackDF, column_LBXTR )\n",
    "asianDF = replace_LBXTR(asianDF, column_LBXTR )\n",
    "multiraceDF = replace_LBXTR (multiraceDF, column_LBXTR )\n",
    "\n",
    "column_LBDLDL = ['LBDLDL']\n",
    "fullDF = replace_LBDLDL(fullDF, column_LBDLDL)\n",
    "nonwhiteDF = replace_LBDLDL(nonwhiteDF, column_LBDLDL )\n",
    "whiteDF = replace_LBDLDL(whiteDF, column_LBDLDL )\n",
    "hispanicDF = replace_LBDLDL(hispanicDF, column_LBDLDL )\n",
    "blackDF = replace_LBDLDL(blackDF, column_LBDLDL )\n",
    "asianDF = replace_LBDLDL(asianDF, column_LBDLDL )\n",
    "multiraceDF = replace_LBDLDL(multiraceDF, column_LBDLDL )\n",
    "\n",
    "column_LBXTC = ['LBXTC']\n",
    "fullDF = replace_LBXTC(fullDF, column_LBXTC)\n",
    "nonwhiteDF = replace_LBXTC(nonwhiteDF, column_LBXTC )\n",
    "whiteDF = replace_LBXTC(whiteDF, column_LBXTC )\n",
    "hispanicDF = replace_LBXTC(hispanicDF, column_LBXTC )\n",
    "blackDF = replace_LBXTC(blackDF, column_LBXTC )\n",
    "asianDF = replace_LBXTC(asianDF, column_LBXTC )\n",
    "multiraceDF = replace_LBXTC(multiraceDF, column_LBXTC )\n",
    "\n",
    "fullDF['newbmi'] = fullDF.apply(calculate_bmi, axis=1)\n",
    "nonwhiteDF['newbmi'] = nonwhiteDF.apply(calculate_bmi, axis=1)\n",
    "whiteDF['newbmi'] = whiteDF.apply(calculate_bmi, axis=1)\n",
    "hispanicDF['newbmi'] = hispanicDF.apply(calculate_bmi, axis=1)\n",
    "blackDF['newbmi'] = blackDF.apply(calculate_bmi, axis=1)\n",
    "asianDF['newbmi'] = asianDF.apply(calculate_bmi, axis=1)\n",
    "multiraceDF['newbmi'] = multiraceDF.apply(calculate_bmi, axis=1)\n",
    "\n",
    "\n",
    "fullDF['abdominal_obesity'] = fullDF.apply(categorize_abdominal_obesity, axis=1)\n",
    "nonwhiteDF['abdominal_obesity'] = nonwhiteDF.apply(categorize_abdominal_obesity, axis=1)\n",
    "whiteDF['abdominal_obesity'] = whiteDF.apply(categorize_abdominal_obesity, axis=1)\n",
    "hispanicDF['abdominal_obesity'] = hispanicDF.apply(categorize_abdominal_obesity, axis=1)\n",
    "blackDF['abdominal_obesity'] = blackDF.apply(categorize_abdominal_obesity, axis=1)\n",
    "asianDF['abdominal_obesity'] = asianDF.apply(categorize_abdominal_obesity, axis=1)\n",
    "multiraceDF['abdominal_obesity'] = multiraceDF.apply(categorize_abdominal_obesity, axis=1)\n",
    "\n",
    "fullDF['bmi_category'] = fullDF['newbmi'].apply(categorize_bmi)\n",
    "nonwhiteDF['bmi_category'] = nonwhiteDF['newbmi'].apply(categorize_bmi)\n",
    "whiteDF['bmi_category'] = whiteDF['newbmi'].apply(categorize_bmi)\n",
    "hispanicDF['bmi_category'] = hispanicDF['newbmi'].apply(categorize_bmi)\n",
    "blackDF['bmi_category'] = blackDF['newbmi'].apply(categorize_bmi)\n",
    "asianDF['bmi_category'] = asianDF['newbmi'].apply(categorize_bmi)\n",
    "multiraceDF['bmi_category'] = multiraceDF['newbmi'].apply(categorize_bmi)\n",
    "\n",
    "column_mean_bmi = ['BMXWAIST']\n",
    "fullDF = replace_mean_bmi(fullDF, column_mean_bmi)\n",
    "nonwhiteDF = replace_mean_bmi(nonwhiteDF, column_mean_bmi )\n",
    "whiteDF = replace_mean_bmi(whiteDF, column_mean_bmi )\n",
    "hispanicDF = replace_mean_bmi(hispanicDF, column_mean_bmi )\n",
    "blackDF = replace_mean_bmi(blackDF, column_mean_bmi )\n",
    "asianDF = replace_mean_bmi(asianDF, column_mean_bmi )\n",
    "multiraceDF = replace_mean_bmi(multiraceDF, column_mean_bmi )\n",
    "\n",
    "mental_health=['DPQ010', 'DPQ020', 'DPQ030', 'DPQ040', 'DPQ050', 'DPQ060','DPQ070','DPQ080', 'DPQ090', 'DPQ100']\n",
    "fullDF['total_mental'] = fullDF[mental_health].sum(axis=1)\n",
    "nonwhiteDF['total_mental'] = nonwhiteDF[mental_health].sum(axis=1)\n",
    "whiteDF['total_mental'] = whiteDF[mental_health].sum(axis=1)\n",
    "hispanicDF['total_mental'] = hispanicDF[mental_health].sum(axis=1)\n",
    "blackDF['total_mental'] = blackDF[mental_health].sum(axis=1)\n",
    "asianDF['total_mental'] = asianDF[mental_health].sum(axis=1)\n",
    "multiraceDF['total_mental'] = multiraceDF[mental_health].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all the null values\n",
    "fullDF= fullDF.dropna(subset= deprCode)\n",
    "whiteDF= whiteDF.dropna(subset= deprCode)\n",
    "nonwhiteDF= nonwhiteDF.dropna(subset= deprCode)\n",
    "hispanicDF= hispanicDF.dropna(subset= deprCode)\n",
    "blackDF= blackDF.dropna(subset= deprCode)\n",
    "asianDF= asianDF.dropna(subset= deprCode)\n",
    "multiraceDF= multiraceDF.dropna(subset= deprCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = fullDF.corr()\n",
    "corr_to_col = corr_matrix['BPQ020']\n",
    "corr_sorted = corr_to_col.abs().sort_values(ascending=False)\n",
    "corr_sorted = corr_sorted[corr_sorted >0.1]\n",
    "n_top = 100  # you can set any number here\n",
    "top_corr_cols = corr_sorted[1:n_top+1].index.tolist()\n",
    "\n",
    "corr_matrix = fullDF.corr()\n",
    "corr_to_col = corr_matrix['BPQ080']\n",
    "corr_sorted = corr_to_col.abs().sort_values(ascending=False)\n",
    "corr_sorted = corr_sorted[corr_sorted >0.1]\n",
    "n_top = 100  # you can set any number here\n",
    "top_corr_cols1 = corr_sorted[1:n_top+1].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_column=['RIDAGEYR', 'RXDDAYS', 'BMXWAIST', 'DMDHHSIZ', 'DMDFMSIZ', 'PAQ710', 'DID040', 'BMXBMI',\n",
    "                  'LBXSUA','LBDSGLSI', 'MCQ180E', 'total_mental', 'PAQ655', 'URDACT', 'URXUMS', 'BPXSY1', 'newbmi', 'BMXWT', 'MCQ180E', 'LBXTC']\n",
    "\n",
    "categorical_column= [word for word in top_corr_cols if word not in numerical_column]\n",
    "\n",
    "#hypertension for model\n",
    "top_corr_cols.append('BPQ020')\n",
    "top_corr_cols.append('LBXTC')\n",
    "top_corr_cols.append('RIAGENDR')\n",
    "top_corr_cols.append('RIDRETH3')\n",
    "\n",
    "fullDF1 = fullDF[top_corr_cols]\n",
    "nonwhiteDF1= nonwhiteDF[top_corr_cols]\n",
    "whiteDF1= whiteDF[top_corr_cols]\n",
    "hispanicDF1= hispanicDF[top_corr_cols]\n",
    "blackDF1= blackDF[top_corr_cols]\n",
    "asianDF1= asianDF[top_corr_cols]\n",
    "multiraceDF1 = multiraceDF[top_corr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_column_chol= ['DID040', 'BMXWAIST', 'LBXTC', 'DMDHHSIZ', 'LBDSGLSI','LBXSCH',  'BPXSY1',\n",
    "                        'MCQ180E', 'DMDFMSIZ', 'LBXSUA', 'PAQ710', 'BMXBMI', 'RXDDAYS', 'LBDLDL', 'RIDAGEYR' ]\n",
    "categorical_column_chol= [word for word in top_corr_cols1 if word not in numerical_column_chol]\n",
    "\n",
    "#cholesterol for model\n",
    "top_corr_cols1.append('BPQ080')\n",
    "top_corr_cols1.append('RIAGENDR')\n",
    "\n",
    "fullDF2 = fullDF[top_corr_cols1]\n",
    "nonwhiteDF2= nonwhiteDF[top_corr_cols1]\n",
    "whiteDF2= whiteDF[top_corr_cols1]\n",
    "hispanicDF2= hispanicDF[top_corr_cols1]\n",
    "blackDF2= blackDF[top_corr_cols1]\n",
    "asianDF2= asianDF[top_corr_cols1]\n",
    "multiraceDF2 = multiraceDF[top_corr_cols1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {\n",
    "    'SEQN': 'Sequence Number',\n",
    "    'RIDRETH3': 'Race/Ethnicity',\n",
    "    'RIAGENDR': 'Gender',\n",
    "    'RIDAGEYR': 'Age (years)',\n",
    "    'DMDBORN4': 'Country of Birth',\n",
    "    'DMDCITZN': 'Citizenship Status',\n",
    "    'DMDMARTL': 'Marital Status',\n",
    "    'DMDEDUC2': 'Education Level',\n",
    "    'DMDHHSIZ': 'Household Size',\n",
    "    'DMDFMSIZ': 'Family Size',\n",
    "    'DBD895': '# of meals not home prepared',\n",
    "    'DBD905': '#_ready-to-eat_foods_30D',\n",
    "    'DBD910': '# of frozen meals/pizza in past 30 days',\n",
    "    'CBD120': 'Money spent on eating out',\n",
    "    'CBD130': 'Money spent on carryout/delivered foods',\n",
    "    'DIQ010': 'Diabetes Diagnosis',\n",
    "    'DID040': 'Age when first told you had diabetes',\n",
    "    'FSDHH': 'Household Food Security',\n",
    "    'FSD032C': 'Could not afford balanced meals',\n",
    "    'PFQ061B': 'Walking for a quarter mile difficulty',\n",
    "    'PFQ061D': 'Stooping, crouching, kneeling difficulty',\n",
    "    'PFQ061E': 'Lifting or carrying difficulty',\n",
    "    'PAQ610': 'Days vigorous work',\n",
    "    'PAQ625': 'Number of days moderate work',\n",
    "    'PAQ640': 'Number of days walk or bicycle',\n",
    "    'PAQ655': 'Days vigorous recreational activities',\n",
    "    'PAQ670': 'Days moderate recreational activities',\n",
    "    'PAQ710': 'Hours watch TV or videos past 30 days',\n",
    "    'PAQ715': 'Hours use computer past 30 days',\n",
    "    'RXDUSE': 'Prescription Drug Use',\n",
    "    'RXDDAYS': 'Prescription Drug Days',\n",
    "    'SLD010H': 'Hours of Sleep',\n",
    "    'SLQ050': 'Sleep Quality',\n",
    "    'SLQ060': 'Sleep Disorder',\n",
    "    'SMD641': '# days smoked cigs during past 30 days',\n",
    "    'SMD650': 'Mental Health Medication Days',\n",
    "    'SMD030': 'Avg # cigarettes/day during past 30 days',\n",
    "    'SMQ858': 'Last 7-d at job someone smoked indoors?\t',\n",
    "    'SMQ872': 'Last 7-d someone smoked in car?',\n",
    "    'SMQ878': 'Last 7-d in other indoor area?',\n",
    "    'BMXBMI': 'Body Mass Index (kg/m²)',\n",
    "    'WHQ070': 'Tried to lose weight in past year',\n",
    "    'WHD080A': 'Ate less food to lose weight',\n",
    "    'WHD080B': 'Switched to foods with lower calories',\n",
    "    'WHD080D': 'Exercised to lose weight',\n",
    "    'WHD080M': 'Drank a lot of water to lose weight',\n",
    "    'MCQ025': 'Age when first had asthma',\n",
    "    'MCQ160A': 'Doctor ever said you had arthritis',\n",
    "    'MCQ180A': 'Age when told you had arthritis',\n",
    "    'MCQ160N': 'Doctor ever told you that you had gout?',\n",
    "    'MCQ180N': 'Age when told you had gout',\n",
    "    'MCQ160C': 'Ever told you had coronary heart disease',\n",
    "    'MCQ180C': 'Doctor ever said you had skin cancer',\n",
    "    'MCQ160D': 'angina/angina pectoris',\n",
    "    'MCQ180D': 'Age when told you had angina pectoris',\n",
    "    'MCQ160E': 'heart attack',\n",
    "    'MCQ180E': 'Age when told you had heart attack',\n",
    "    'MCQ160F': 'stroke',\n",
    "    'MCQ180F': 'Age when told you had a stroke',\n",
    "    'MCQ220': 'cancer/malignancy',\n",
    "    'BPXSY1': 'Blood Pressure - Systolic (1st)',\n",
    "    'BPXDI1': 'Blood Pressure - Diastolic (1st)',\n",
    "    'BPQ080': 'Hypercholestrolemia',\n",
    "    'LBXTR': 'Triglycerides (mg/dL)',\n",
    "    'LBDLDL': 'LDL Cholesterol (mg/dL)',\n",
    "    'LBXTC': 'Total Cholesterol (mg/dL)',\n",
    "    'INDHHIN2': 'Household Income',\n",
    "    'INDFMIN2': 'Family Income',\n",
    "    'BPQ020': 'hypertension',\n",
    "    'BMXWT': 'Weight (kg)',\n",
    "    'BMXHT': 'Height (cm)',\n",
    "    'DIQ050': 'Insulin',\n",
    "    'DIQ175A': 'Family history Diabetes',\n",
    "    'BMXWAIST': 'Waist Circumference (cm)',\n",
    "    'DBD900': '# of meals from fast food or pizza place',\n",
    "    'CBQ505': 'Eat at fast food/pizza places',\n",
    "    'CBQ535': 'Saw nutrition info on fast food menu',\n",
    "    'DPQ010': 'Little Interest in Doing Things',\n",
    "    'DPQ020': 'Feeling Down, Depressed, or Hopeless',\n",
    "    'DPQ030': 'Trouble Sleeping or Sleeping Too Much',\n",
    "    'DPQ040': 'Feeling Tired or Having Little Energy',\n",
    "    'DPQ050': 'Poor Appetite or Overeating',\n",
    "    'DPQ060': 'Feeling Bad About Yourself',\n",
    "    'DPQ070': 'Trouble Concentrating on Things',\n",
    "    'DPQ080': 'Moving or Speaking Slowly or Too Fast',\n",
    "    'DPQ090': 'Thought you would be better off dead\t',\n",
    "    'DPQ100': 'Difficulty these problems have caused',\n",
    "    'ALQ120Q': 'Alcohol Consumption Frequency',\n",
    "    'URXUMS': 'Albumin, urine (mg/L)',\n",
    "    'URDACT': 'First albumin creatinine ratio (mg/g)',\n",
    "    'LBXSTR': 'Triglycerides (mg/dL)',\n",
    "    'LBXSUA': 'Uric acid (mg/dL)',\n",
    "    'LBXSCH': 'Cholesterol (mg/dL)',\n",
    "    'LBDSGLSI': 'Glucose, refrigerated serum (mmol/L)',\n",
    "    'DR1TKCAL': 'Energy (kcal)',\n",
    "    'DR1TCARB': 'Carbohydrate (gm)',\n",
    "    'DR1TSUGR': 'Total sugars (gm)',\n",
    "    'newbmi': 'New BMI',\n",
    "    'abdominal_obesity': 'Abdominal Obesity',\n",
    "    'bmi_category': 'BMI Category',\n",
    "    'total_mental': 'Total Mental Health Score'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "fullDF1.rename(columns=column_names, inplace=True)\n",
    "nonwhiteDF1.rename(columns=column_names, inplace=True)\n",
    "whiteDF1.rename(columns=column_names, inplace=True)\n",
    "hispanicDF1.rename(columns=column_names, inplace=True)\n",
    "blackDF1.rename(columns=column_names, inplace=True)\n",
    "asianDF1.rename(columns=column_names, inplace=True)\n",
    "multiraceDF1.rename(columns=column_names, inplace=True)\n",
    "\n",
    "fullDF2.rename(columns=column_names, inplace=True)\n",
    "nonwhiteDF2.rename(columns=column_names, inplace=True)\n",
    "whiteDF2.rename(columns=column_names, inplace=True)\n",
    "hispanicDF2.rename(columns=column_names, inplace=True)\n",
    "blackDF2.rename(columns=column_names, inplace=True)\n",
    "asianDF2.rename(columns=column_names, inplace=True)\n",
    "multiraceDF2.rename(columns=column_names, inplace=True)\n",
    "\n",
    "fullDF.rename(columns=column_names, inplace=True)\n",
    "nonwhiteDF.rename(columns=column_names, inplace=True)\n",
    "whiteDF.rename(columns=column_names, inplace=True)\n",
    "hispanicDF.rename(columns=column_names, inplace=True)\n",
    "blackDF.rename(columns=column_names, inplace=True)\n",
    "asianDF.rename(columns=column_names, inplace=True)\n",
    "multiraceDF.rename(columns=column_names, inplace=True)\n",
    "\n",
    "demographics= ['RIAGENDR', 'RIDAGEYR','RIDRETH3', 'DMDCITZN', 'DMDMARTL', 'DMDEDUC2', 'DMDHHSIZ', 'DMDFMSIZ', 'INDHHIN2', 'Bmi_category','newbmi', 'BPQ020']\n",
    "demographic_categorical=['RIAGENDR','RIDRETH3', 'DMDCITZN', 'DMDMARTL', 'DMDEDUC2', 'INDHHIN2']\n",
    "demographic_numerical= ['RIDAGEYR', 'newbmi','BPXSY1', 'newbmi', 'total_mental', 'BMXWAIST', 'LBXTC']\n",
    "legend_category=('BPQ020', 'BPQ080', 'MCQ160C',  'MCQ220', 'MCQ160N', 'DIQ010')\n",
    "\n",
    "demographics = [column_names.get(col, col) for col in demographics]\n",
    "demographic_categorical = [column_names.get(col, col) for col in demographic_categorical]\n",
    "demographic_numerical = [column_names.get(col, col) for col in demographic_numerical]\n",
    "legend_category = [column_names.get(col, col) for col in legend_category]\n",
    "categorical_column_chol = [column_names.get(col, col) for col in categorical_column_chol]\n",
    "categorical_column = [column_names.get(col, col) for col in categorical_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_final = {\n",
    "    'Age (years)': 'age',\n",
    "    'Race/Ethnicity':'race',\n",
    "    'Blood Pressure - Systolic (1st)': 'bpSys',\n",
    "    'Hypercholestrolemia': 'cholesterol',\n",
    "    'Stooping, crouching, kneeling difficulty': 'crouchDiff',\n",
    "    'Doctor ever said you had arthritis': 'arthritis',\n",
    "    'Diabetes Diagnosis': 'diabetes',\n",
    "    'Waist Circumference (cm)': 'waistCirc',\n",
    "    'Body Mass Index (kg/m²)': 'bmi',\n",
    "    'Hours watch TV or videos past 30 days': 'tvHours',\n",
    "    'Ever told you had coronary heart disease': 'coronaryHeartDisease',\n",
    "    'Sleep Quality': 'sleepQuality',\n",
    "    'Household Size': 'householdSize',\n",
    "    'heart attack': 'heartAttack',\n",
    "    'Walking for a quarter mile difficulty': 'walkDiff',\n",
    "    'Family Size': 'familySize',\n",
    "    'cancer/malignancy': 'cancer',\n",
    "    'stroke': 'stroke',\n",
    "    'Sleep Disorder': 'sleepDisorder',\n",
    "    'Doctor ever told you that you had gout?': 'gout',\n",
    "    'Total Mental Health Score': 'mentalHealthScore',\n",
    "    'Days vigorous recreational activities': 'vigorousActivities',\n",
    "    'Marital Status': 'maritalStatus',\n",
    "    'Little Interest in Doing Things': 'interestInDoingThings',\n",
    "    'Feeling Tired or Having Little Energy': 'tiredOrLowEnergy',\n",
    "    'Feeling Down, Depressed, or Hopeless': 'depressedOrHopeless',\n",
    "    'angina/angina pectoris': 'angina',\n",
    "    'Trouble Sleeping or Sleeping Too Much': 'troubleSleeping',\n",
    "    'Trouble Concentrating on Things': 'troubleConcentrating',\n",
    "    'hypertension': 'hypertension',\n",
    "    'Gender': 'gender',\n",
    "    'Glucose, refrigerated serum (mmol/L)': 'glucose_level',\n",
    "}\n",
    "\n",
    "column_names_replace = [\n",
    "    'age',\n",
    "    'race',\n",
    "    'gender',\n",
    "    'maritalStatus',\n",
    "    'householdSize',\n",
    "    'familySize',\n",
    "    'bpSys',\n",
    "    'cholesterol',\n",
    "    'waistCirc',\n",
    "    'bmi',\n",
    "    'arthritis',\n",
    "    'diabetes',\n",
    "    'coronaryHeartDisease',\n",
    "    'heartAttack',\n",
    "    'cancer',\n",
    "    'stroke',\n",
    "    'gout',\n",
    "    'hypertension',\n",
    "    'angina',\n",
    "    'crouchDiff',\n",
    "    'walkDiff',\n",
    "    'vigorousActivities',\n",
    "    'mentalHealthScore',\n",
    "    'interestInDoingThings',\n",
    "    'tiredOrLowEnergy',\n",
    "    'depressedOrHopeless',\n",
    "    'troubleConcentrating',\n",
    "    'sleepQuality',\n",
    "    'tvHours',\n",
    "    'sleepDisorder',\n",
    "    'troubleSleeping',\n",
    "    'glucose_level'\n",
    "]\n",
    "\n",
    "column_names_ML = [\n",
    "    #demographics\n",
    "    'age',\n",
    "    'race',\n",
    "    'gender',\n",
    "    'maritalStatus',\n",
    "    'householdSize',\n",
    "    #health_parameters\n",
    "    'bpSys',\n",
    "    'cholesterol',\n",
    "    'glucose_level',\n",
    "    'bmi',\n",
    "    #disease_history\n",
    "    'arthritis',\n",
    "    'diabetes',\n",
    "    'heartAttack',\n",
    "    'stroke',\n",
    "    'hypertension',\n",
    "    \n",
    "    #physical_activity_mental_health\n",
    "    'walkDiff',\n",
    "    'interestInDoingThings',\n",
    "    'tiredOrLowEnergy',\n",
    "    'depressedOrHopeless',\n",
    "    'troubleSleeping' \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF= fullDF1.rename(columns=column_names_final)\n",
    "newDF= newDF[column_names_replace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping dictionaries\n",
    "gender_mapping = {2: 'Female', 1: 'Male'}\n",
    "marital_status_mapping = {1: 'Married', 2: 'Widowed', 3: 'Divorced', 4: 'Separated', 5: 'Single', 6: 'Living with Partner'}\n",
    "binary_mapping = {0: 'No', 1: 'Yes'}\n",
    "difficulty_mapping = {1: 'No Difficulty', 2: 'Some Difficulty', 3: 'Much Difficulty', 4: 'Unable to do', 5: 'Do not do this activity'}\n",
    "tv_hours_mapping = {0: 'Less than 1 hour', 1: '1 hour', 2: '2 hours', 3: '3 hours', 4: '4 hours', 5: '5 hours or more', 8: 'Don\\'t watch TV'}\n",
    "diabetes_mapping = {2: 'Diabetes', 1: 'Pre-diabetes', 0: 'No Diabetes'}\n",
    "sleep_mapping = {0: 'Not at all', 1: 'Several Days', 2: 'More than half the days', 3: 'Nearly every day'}\n",
    "racial_mapping = {1: 'Mexican American', 2: 'Other Hispanic', 3: 'White', 4: 'Black', 6: 'Asian', 7: 'Others'}\n",
    "family_mapping = {1: 'Alone', 2: '2 people', 3: '3 people', 4: '4 people', 5: '5 people', 6: '6 people', 7: '7 or more people'}\n",
    "\n",
    "df_viz = newDF.copy()\n",
    "\n",
    "# Replace numerical values with text\n",
    "df_viz['gender'] = newDF['gender'].replace(gender_mapping)\n",
    "df_viz['maritalStatus'] = newDF['maritalStatus'].replace(marital_status_mapping)\n",
    "df_viz['cholesterol'] = newDF['cholesterol'].replace(binary_mapping)\n",
    "df_viz['arthritis'] = newDF['arthritis'].replace(binary_mapping)\n",
    "df_viz['coronaryHeartDisease'] = newDF['coronaryHeartDisease'].replace(binary_mapping)\n",
    "df_viz['heartAttack'] = newDF['heartAttack'].replace(binary_mapping)\n",
    "df_viz['cancer'] = newDF['cancer'].replace(binary_mapping)\n",
    "df_viz['stroke'] = newDF['stroke'].replace(binary_mapping)\n",
    "df_viz['gout'] = newDF['gout'].replace(binary_mapping)\n",
    "df_viz['hypertension'] = newDF['hypertension'].replace(binary_mapping)\n",
    "df_viz['angina'] = newDF['angina'].replace(binary_mapping)\n",
    "df_viz['crouchDiff'] = newDF['crouchDiff'].replace(difficulty_mapping)\n",
    "df_viz['walkDiff'] = newDF['walkDiff'].replace(difficulty_mapping)\n",
    "df_viz['tvHours'] = newDF['tvHours'].replace(tv_hours_mapping)\n",
    "df_viz['sleepDisorder'] = newDF['sleepDisorder'].replace(binary_mapping)\n",
    "df_viz['troubleSleeping'] = newDF['troubleSleeping'].replace(sleep_mapping)\n",
    "df_viz['diabetes'] = newDF['diabetes'].replace(diabetes_mapping)\n",
    "df_viz['race'] = newDF['race'].replace(racial_mapping)\n",
    "df_viz['familySize'] = newDF['familySize'].replace(family_mapping)\n",
    "\n",
    "print(df_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF.to_csv(\"updatedDF.csv\", index=False)\n",
    "df_viz.to_csv(\"vizDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = newDF.copy()\n",
    "\n",
    "gender_mapping_ml = {2: 0, 1: 1}\n",
    "diabetes_mapping_ml = {2: 1, 1: 2}\n",
    "\n",
    "\n",
    "df_ml['gender'] = newDF['gender'].replace(gender_mapping_ml)\n",
    "df_ml['maritalStatus'] = newDF['maritalStatus'].replace(marital_status_mapping)\n",
    "df_ml['race'] = newDF['race'].replace(racial_mapping)\n",
    "df_ml['diabetes'] = newDF['diabetes'].replace(diabetes_mapping_ml)\n",
    "\n",
    "df_ml= df_ml[column_names_ML]\n",
    "df_ml['race'] = df_ml['race'].astype('category')\n",
    "df_ml['maritalStatus'] = df_ml['maritalStatus'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.to_csv(\"mlDF.csv\", index=False)\n",
    "df_ml.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, dtype=int)  # Initialize the encoder\n",
    "encoded_cols = encoder.fit_transform(df_ml[['race', 'maritalStatus']])  # Fit and transform the selected columns\n",
    "encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(['race', 'maritalStatus']))  # Create a DataFrame from the encoded columns\n",
    "\n",
    "# Concatenate the original DataFrame with the encoded DataFrame\n",
    "df_ml_one_hot = pd.concat([df_ml.drop(['race', 'maritalStatus'], axis=1), encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes         1.000000\n",
       "glucose_level    0.421341\n",
       "cholesterol      0.255820\n",
       "age              0.254105\n",
       "hypertension     0.252963\n",
       "bmi              0.182417\n",
       "heartAttack      0.163205\n",
       "arthritis        0.155529\n",
       "bpSys            0.146487\n",
       "stroke           0.112175\n",
       "Name: diabetes, dtype: float64"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df_ml.corr()\n",
    "corr_to_col = corr_matrix['diabetes']\n",
    "corr_sorted = corr_to_col.abs().sort_values(ascending=False)\n",
    "corr_sorted = corr_sorted[corr_sorted >0.1]\n",
    "n_top = 100  \n",
    "top_corr_cols = corr_sorted[1:n_top+1].index.tolist()\n",
    "\n",
    "corr_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                     int64\n",
       "gender                                  int64\n",
       "householdSize                           int64\n",
       "bpSys                                 float64\n",
       "cholesterol                           float64\n",
       "glucose_level                         float64\n",
       "bmi                                   float64\n",
       "arthritis                             float64\n",
       "diabetes                             category\n",
       "heartAttack                           float64\n",
       "stroke                                float64\n",
       "hypertension                          float64\n",
       "walkDiff                              float64\n",
       "interestInDoingThings                 float64\n",
       "tiredOrLowEnergy                      float64\n",
       "depressedOrHopeless                   float64\n",
       "troubleSleeping                       float64\n",
       "race_Asian                              int32\n",
       "race_Black                              int32\n",
       "race_Mexican American                   int32\n",
       "race_Other Hispanic                     int32\n",
       "race_Others                             int32\n",
       "race_White                              int32\n",
       "maritalStatus_Divorced                  int32\n",
       "maritalStatus_Living with Partner       int32\n",
       "maritalStatus_Married                   int32\n",
       "maritalStatus_Separated                 int32\n",
       "maritalStatus_Single                    int32\n",
       "maritalStatus_Widowed                   int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml_one_hot['diabetes'] = df_ml_one_hot['diabetes'].astype('category')\n",
    "(df_ml_one_hot.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_ml= df_ml_one_hot[df_ml_one_hot['diabetes'].isin([1, 0])]\n",
    "df_final_ml['diabetes'] = df_final_ml['diabetes'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Processing\n",
    "X_other= df_final_ml.drop(['diabetes'], axis= 1)\n",
    "y_other= df_final_ml['diabetes']\n",
    "\n",
    "cols = X_other.columns\n",
    "index = X_other.index\n",
    "\n",
    "transformer = StandardScaler().fit(X_other)\n",
    "X_other = transformer.transform(X_other)\n",
    "X_other = pd.DataFrame(X_other, columns = cols, index = index)\n",
    "\n",
    "x_train_other,x_test_other,y_train_other,y_test_other = train_test_split(X_other,y_other,test_size=0.3,random_state=96)\n",
    "\n",
    "#Synthetic Minority Oversampling Technique: To address the class imbalance problem, we will use the SMOTE technique to oversample the minority class.\n",
    "\n",
    "sm_other = SMOTE()\n",
    "\n",
    "X_res_other, y_res_other = sm_other.fit_resample(x_train_other, y_train_other)\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_other==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_other==0)))\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_res_other.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res_other.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res_other==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res_other==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of ML Models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=12345)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier(random_state=12345)))\n",
    "models.append(('RF', RandomForestClassifier(random_state=12345)))\n",
    "models.append(('SVM', SVC(gamma='auto', random_state=12345)))\n",
    "models.append(('XGB', GradientBoostingClassifier(random_state=12345)))\n",
    "models.append((\"LightGBM\", LGBMClassifier(random_state=12345, verbosity=-1)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "# Perform cross-validation on all the models\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_res_other, y_res_other, cv=10, scoring=\"accuracy\")\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# Visualizing the cross-validation scores using a boxplot\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Neural Network Model (Keras)\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(28,), activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with a different optimizer and learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Assuming X_res_other and y_res_other are your training features and labels respectively\n",
    "# and x_test_other and y_test_other are your test features and labels respectively\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_res_other, y_res_other, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test_other, y_test_other, verbose=2)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Assuming model.predict returns probabilities\n",
    "y_pred_prob = model.predict(x_test_other)\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_other, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Voting Classifier with Neural Network and Random Forest\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_res_other), y=y_res_other)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Define the neural network model\n",
    "def create_nn_model():\n",
    "    model = Sequential([\n",
    "        Dense(64, input_shape=(28,), activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model for use in scikit-learn\n",
    "nn_model = KerasClassifier(build_fn=create_nn_model, epochs=100, batch_size=32, validation_split=0.2, class_weight=class_weights_dict, verbose=0)\n",
    "\n",
    "# Train the neural network model\n",
    "nn_model.fit(X_res_other, y_res_other)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_res_other, y_res_other)\n",
    "\n",
    "# Combine the models using a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[('nn', nn_model), ('rf', rf)], voting='soft')\n",
    "\n",
    "# Train the VotingClassifier\n",
    "voting_clf.fit(X_res_other, y_res_other)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "pred = voting_clf.predict(x_test_other)\n",
    "print(classification_report(y_test_other, pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test_other, pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model\n",
    "\n",
    "#Define the parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 300, 500, 1000],\n",
    "    'max_features': [ 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_distributions, n_iter=50, cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
    "\n",
    "#Fit the model on the resampled data\n",
    "random_search.fit(X_res_other, y_res_other)\n",
    "\n",
    "#Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "#Initialize a new RandomForestClassifier with the best parameters\n",
    "best_rf = RandomForestClassifier(**best_params)\n",
    "\n",
    "#Fit this new model on the training data\n",
    "best_rf.fit(X_res_other, y_res_other)\n",
    "\n",
    "#Make predictions and evaluate the model\n",
    "pred = best_rf.predict(x_test_other)\n",
    "print(classification_report(y_test_other, pred))\n",
    "\n",
    "#Get the mean cross-validation score\n",
    "mean_cv_score = random_search.best_score_\n",
    "print(f\"Mean Cross-Validation Score: {mean_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for LightGBM\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500, 1000],\n",
    "    'max_depth': [-1, 10, 20, 30],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'boosting_type': ['gbdt', 'dart']\n",
    "}\n",
    "\n",
    "#Initialize the LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "#Initialize GridSearchCV\n",
    "grid_search = RandomizedSearchCV(estimator=lgbm, param_distributions=param_distributions, n_iter=50, cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
    "\n",
    "# Fit the model on the resampled data\n",
    "grid_search.fit(X_res_other, y_res_other)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Initialize a new LGBMClassifier with the best parameters\n",
    "best_lgbm = LGBMClassifier(**best_params)\n",
    "\n",
    "# Fit this new model on the training data\n",
    "best_lgbm.fit(X_res_other, y_res_other)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "pred = best_lgbm.predict(x_test_other)\n",
    "print(classification_report(y_test_other, pred))\n",
    "\n",
    "# Calculate the mean cross-validation score\n",
    "cv_scores = cross_val_score(best_lgbm, X_res_other, y_res_other, cv=10)\n",
    "print(\"Mean Cross-Validation Score:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_other, pred, labels=best_rf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_rf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_prob = best_rf.predict_proba(x_test_other)[:,1]\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_other, y_prob)\n",
    "roc_auc = roc_auc_score(y_test_other, y_prob)\n",
    "\n",
    "plt.plot(false_positive_rate, true_positive_rate, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model as a .pkl file\n",
    "joblib.dump(model, 'your_trained_model.pkl')\n",
    "# Save the StandardScaler object as a .pkl file\n",
    "joblib.dump(transformer, 'your_scaler.pkl')\n",
    "# Save the OneHotEncoder object as a .pkl file\n",
    "joblib.dump(encoder, 'your_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing one hot encoding as pickle file\n",
    "\n",
    "form_data = {\n",
    "    \"age\": 30,\n",
    "    \"race\": \"White\",\n",
    "    \"gender\": 1,\n",
    "    \"maritalStatus\": \"Married\",\n",
    "    \"householdSize\": 3,\n",
    "    \"bpSys\": 120,\n",
    "    \"cholesterol\": 1,\n",
    "    \"glucose_level\": 90,\n",
    "    \"bmi\": 25.5,\n",
    "    \"arthritis\": 0,\n",
    "    \"diabetes\": 0,\n",
    "    \"heartAttack\": 0,\n",
    "    \"stroke\": 0,\n",
    "    \"hypertension\": 1,\n",
    "    \"walkDiff\": 2,\n",
    "    \"interestInDoingThings\": 1,\n",
    "    \"tiredOrLowEnergy\": 2,\n",
    "    \"depressedOrHopeless\": 0,\n",
    "    \"troubleSleeping\": 1\n",
    "}\n",
    "\n",
    "# Defining the list of columns as per the HTML form\n",
    "input_features = [\n",
    "    'age',\n",
    "    'race',\n",
    "    'gender',\n",
    "    'maritalStatus',\n",
    "    'householdSize',\n",
    "    'bpSys',\n",
    "    'cholesterol',\n",
    "    'glucose_level',\n",
    "    'bmi',\n",
    "    'arthritis',\n",
    "    'diabetes',\n",
    "    'heartAttack',\n",
    "    'stroke',\n",
    "    'hypertension',\n",
    "    'walkDiff',\n",
    "    'interestInDoingThings',\n",
    "    'tiredOrLowEnergy',\n",
    "    'depressedOrHopeless',\n",
    "    'troubleSleeping'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with one row from the form data\n",
    "df = pd.DataFrame([form_data])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the one hot encoding\n",
    "encoder2 = joblib.load('your_encoder.pkl')\n",
    "\n",
    "# Select the specific columns to be transformed\n",
    "columns_to_transform = ['race', 'maritalStatus']\n",
    "df_selected = df[columns_to_transform]\n",
    "\n",
    "# Transform the selected columns\n",
    "transformed_data = encoder2.transform(df_selected)\n",
    "\n",
    "# Get feature names (assuming the encoder supports get_feature_names_out)\n",
    "feature_names = encoder2.get_feature_names_out(columns_to_transform)\n",
    "\n",
    "# Convert the transformed data to a DataFrame\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=feature_names)\n",
    "\n",
    "# Drop the original columns that were transformed\n",
    "df.drop(columns=columns_to_transform, inplace=True)\n",
    "\n",
    "# Concatenate the transformed columns with the original dataframe\n",
    "df_ml_transformed = pd.concat([df, transformed_df], axis=1)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(df_ml_transformed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
